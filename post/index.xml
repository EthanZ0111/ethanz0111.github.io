<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on My New Hugo Site</title>
    <link>/post/</link>
    <description>Recent content in Posts on My New Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jun 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MongoDB mapreduce 调试</title>
      <link>/post/2017-06-16-mongodb-mapreduce/</link>
      <pubDate>Fri, 16 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-06-16-mongodb-mapreduce/</guid>
      <description>#MongoDB 相关函数用与调试方法。
var c = db.UIDs.findOne() var m = function(){ print(this) this.DS.forEach(function(z){ print(z.D,z.C); emit(z.D,z.C); }); } var emit = function(key, value) { print(&amp;quot;emit&amp;quot;); print(&amp;quot;key: &amp;quot; + key + &amp;quot; value: &amp;quot; + tojson(value)); } m.apply(c)//调试 var r = function(key,values){return Array.sum(values);} db.UIDs.mapReduce(m,r,{limit:1000,out:&amp;quot;null&amp;quot;}).find() 引用自：
跟踪调试
MongoDB mapReduce使用 
MongoDB mapReduce使用</description>
    </item>
    
    <item>
      <title>kafka 监控</title>
      <link>/post/2017-06-01-kafka-offset-monitor/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-06-01-kafka-offset-monitor/</guid>
      <description>kafka监控工具 kafka-manager,配置复杂,功能强大
Kafka Offset Monitor,配置简单,图形界面监控详细日志读写情况与lag信息.但要使用最新版,官网链接的git项目已经不在更新,可使用
Kafka Offset Monitor</description>
    </item>
    
    <item>
      <title>Storm 配置相关</title>
      <link>/post/2017-05-31-storm-configure/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-05-31-storm-configure/</guid>
      <description>日志相关 使用本地模式的时候,能够指定相应的配置文件来控制日志(log4j2)的输出情况.
但是使用集群模式,将jar文件上传到storm集群后,日志的配置文件将使用storm环境指定的日志配置文件,目前使用的是log4j2.存在于storm项目目录下的log4j2/worker.xml,如果想要控制日志输出,需要修改这个配置文件.
ps:如果配置文件出错,将导致日志无法输出,storm ui 页面无法统计单节点错误信息.需要在本地模式进行配置文件的调试.
内存占用 首先理解storm中topology,bolt/sprot,worker,executor,task的关系.
Storm 性能优化
Understanding the Parallelism of a Storm Topology
Concepts
然后,默认情况下,storm集群给一个worker分配64(日志使用)+768M的内存空间,如果需要修改,则可以在配置文件(conf/storm.yaml)中,增加配置项:worker.heap.memory.mb: 1984(不包含日志的64M).但要注意的是,最好是集群中所有的storm节点都进行配置,因为这个配置项(或许可以扩展到全部配置项),默认会使用leader节点的信息,如果当前的storm节点不是leader(storm ui中查看),修改不会起作用.</description>
    </item>
    
    <item>
      <title>Java log4j2 配置相关</title>
      <link>/post/2017-05-05-java-log4j2-configure/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-05-05-java-log4j2-configure/</guid>
      <description>java新日志系统log4j2配置相关 根据代码运行情况,目前得到的信息是如果使用java api提供的接口:
返回的log对象,是从全局的一个LoggerFactory中实例出来的对象,相应的配置信息会从全局的LoggerContext中获取(搭载使用log4j2日志系统).
如果需要修改这些配置,则需要按照如下方式,先获取到全局的LoggerContext,然后使用相应的接口进行配置的rewrite.
How do I reconfigure log4j2 in code with a specific configuration file?
See the below example. Be aware that this LoggerContext class is not part of the public API so your code may break with any minor release. 来源,官网FAQ
// import org.apache.logging.log4j.core.LoggerContext; LoggerContext context = (org.apache.logging.log4j.core.LoggerContext) LogManager.getContext(false); File file = new File(&amp;quot;path/to/a/different/log4j2.xml&amp;quot;); // this will force a reconfiguration context.setConfigLocation(file.toURI()); </description>
    </item>
    
    <item>
      <title>Spark Storm Hadoop</title>
      <link>/post/2017-04-01-spark-storm-hadoop/</link>
      <pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-04-01-spark-storm-hadoop/</guid>
      <description>Hadoop vs Storm 以下内容摘录自：
Hadoop实质上更多是一个分布式数据基础设施: 它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储。Hadoop还会索引和跟踪这些数据，让大数据处理和分析效率达到前所未有的高度。 Spark，则是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储。
相反，Spark也不是非要依附在Hadoop身上才能生存，但它没有提供文件管理系统。所以，它必须和其他的分布式文件系统进行集成才能运作。这里我们可以选择Hadoop的HDFS,也可以选择其他的基于云的数据系统平台。但Spark默认来说还是被用在Hadoop上面的，毕竟，大家都认为它们的结合是最好的。
MapReduce是分步对数据进行处理的: ”从集群中读取数据，进行一次处理，将结果写到集群，从集群中读取更新后的数据，进行下一次的处理，将结果写到集群，等等…“ Booz Allen Hamilton的数据科学家Kirk Borne如此解析。
反观Spark，它会在内存中以接近“实时”的时间完成所有的数据分析：“从集群中读取数据，完成所有必须的分析处理，将结果写回集群，完成，” Born说道。Spark的批处理速度比MapReduce快近10倍，内存中的数据分析速度则快近100倍。
如果需要处理的数据和结果需求大部分情况下是静态的，且你也有耐心等待批处理的完成的话，MapReduce的处理方式也是完全可以接受的。 但如果你需要对流数据进行分析，比如那些来自于工厂的传感器收集回来的数据，又或者说你的应用是需要多重数据处理的，那么你也许更应该使用Spark进行处理。 大部分机器学习算法都是需要多重数据处理的。此外，通常会用到Spark的应用场景有以下方面：实时的市场活动，在线产品推荐，网络安全分析，机器日记监控等。
Spark 有待补充</description>
    </item>
    
    <item>
      <title>Linux shell使用</title>
      <link>/post/2017-03-31-linux-shell-usage/</link>
      <pubDate>Fri, 31 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-03-31-linux-shell-usage/</guid>
      <description>&lt;p&gt;Linux常用命令收集&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>多种代理服务理解</title>
      <link>/post/2017-03-23-proxy-type/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-03-23-proxy-type/</guid>
      <description>&lt;h1 id=&#34;代理服务器类型&#34;&gt;代理服务器类型&lt;/h1&gt;
&lt;p&gt;代理服务器的个人总结。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>